# ğŸ™ï¸ General AI Voice Assistant Template

<div align="center">

**A Real-Time, General-Purpose AI Voice Agent**
*Powered by Azure OpenAI & Azure Speech*

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](Dockerfile)
[![Azure](https://img.shields.io/badge/Azure-Cloud-0078D4.svg)](https://azure.microsoft.com/)

</div>

---

## ğŸ“– Overview

This is a **low-latency voice assistant template** designed as a clean starting point for building custom voice agents. It combines real-time streaming speech processing (STT/TTS) with Azure OpenAI for intelligent responses.

It features a modern, responsive UI with **AR (Black)** and **Light (White)** modes, and dynamic context switching between Voice and Chat interactions.

### ğŸšœ Looking for the Farmer Implementation?
This template was derived from a specialized USDA Farmer Grant Assistant. If you are looking for an example of how to integrate **MCP Tools** (Function Calling) for real-world use cases (like PDF form filling, API data fetching, etc.), please refer to the original implementation:

ğŸ‘‰ **[Voicebot Farmer Grants Repository](https://github.com/Banudeep/Voicebot-Farmer-Grants)**

---

## ï¿½ï¸ Architecture

![Architecture Diagram](images/Voicebot-Cascading-architecture-diag.png)

---

## ï¿½ğŸŒŸ Key Features

### âš¡ Real-Time Interaction
- **Low Latency:** Optimized streaming pipeline for near-instant voice responses.
- **Interruption Handling:** Capable of handling interruptions naturally.

### ğŸ¨ Modern UI
- **Dual Visual Modes:**
    - **AR Mode:** Pure black interface optimized for AR glasses or OLED screens.
    - **Light Mode:** Clean, high-contrast white interface.
- **Dynamic Icons:** Interface elements (Microphone/Chat Bubble) adapt based on the active input mode.

### ğŸ§  General Purpose
- **Clean Slate:** No domain-specific tools pre-installed.
- **Cascading Architecture:** Modular design separating STT, LLM, and TTS streams.
    > *Interesting in an end-to-end Speech-to-Speech approach using the **GPT Realtime API**? Check out the [Voicebot STS Repository](https://github.com/Banudeep/Voicebot-STS) for an alternative architecture.*
- **Extensible:** Ready for you to add your own tools and system prompts.

---

## ğŸš€ Quick Start

### 1. Requirements
- **Docker** (Recommended) or Python 3.11+
- **Azure OpenAI Service** (GPT-4o or similiar)
- **Azure Speech Service** (Key & Region)

### 2. Configuration
Copy the example environment file and fill in your keys:

```bash
cp .env.example .env
```
*See `.env.example` for details on API keys.*

### 3. Run with Docker
The easiest way to run the full stack:

```bash
docker compose up --build
```
Open your browser to **http://localhost:8080** and click "Connect".

---

## ğŸ› ï¸ Project Structure

```
voice_agent/
â”œâ”€â”€ web_voice_agent.py          # ğŸš€ Main WebSocket Server & Orchestrator
â”œâ”€â”€ llm_stream.py               # ğŸ§  Azure OpenAI Manager
â”œâ”€â”€ stt_stream.py               # ğŸ¤ Speech-to-Text Stream Handler
â”œâ”€â”€ tts_stream.py               # ğŸ”Š Text-to-Speech Stream Handler
â”œâ”€â”€ config.py                   # âš™ï¸ Configuration & Environment Loading
â”œâ”€â”€ mcp_tools/                  # ğŸ§© Tool Directory (Empty Template)
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ general.yml             # ğŸ­ General System Prompt
â”œâ”€â”€ web_ui/                     # ğŸŒ Frontend Interface
â”‚   â”œâ”€â”€ voice_agent.html
â”‚   â””â”€â”€ audio-processor.js
â””â”€â”€ docker-compose.yml          # ğŸ³ Container Orchestration
```

## ğŸ”’ Security & Privacy
- **No Data Retention:** Voice audio is processed in memory (unless recording is explicitly enabled).
- **Azure Security:** Relies on enterprise-grade Azure Cognitive Services.

---